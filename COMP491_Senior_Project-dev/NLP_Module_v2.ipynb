{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP_Module_v2.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"5cnvcTIXJMab","colab_type":"code","outputId":"1ac4d184-3979-4105-ea8c-8d6c75acfbba","executionInfo":{"status":"ok","timestamp":1573826824595,"user_tz":-180,"elapsed":9065,"user":{"displayName":"Ceren A","photoUrl":"","userId":"03971231441041698356"}},"colab":{"base_uri":"https://localhost:8080/","height":88}},"source":["## Installation required when using Google Colab\n","!pip install webcolors\n","!pip install word2number\n","!pip install -r requirements.txt"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: webcolors in /usr/local/lib/python3.6/dist-packages (1.10)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from webcolors) (1.12.0)\n","Requirement already satisfied: word2number in /usr/local/lib/python3.6/dist-packages (1.1)\n","\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8t77NLojKLp-","colab_type":"code","colab":{}},"source":["## Imports\n","import spacy\n","from spacy import displacy\n","import webcolors\n","from word2number import w2n\n","import json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6QaB_EYMFDD","colab_type":"code","colab":{}},"source":["## Object to be used in Sketching module. Contains the necessary details \n","# Find another name?\n","class Object:\n","  def __init__(self, name, color=\"white\", size=1, number = 1, location=\"random\"):\n","    self.name = name\n","    self.color = color\n","    self.size = size\n","    self.number = number\n","    self.location = location\n","  \n","  def print(self):\n","    print(\"Name: \",self.name,\"\\tColor:\",self.color,\" Size:\",self.size,\" Number:\",self.number,\" Location:\",self.location)\n","\n","  def to_json(self):\n","    return json.dumps(self.__dict__)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcLLaBpVf6Wt","colab_type":"code","colab":{}},"source":["## Functions to identify what information a feature gives about the object\n","def isColor(feature):\n","  return feature in webcolors.CSS3_NAMES_TO_HEX\n","\n","def isNumber(feature):\n","  try:\n","    w2n.word_to_num(feature)\n","    return True\n","  except:\n","    return False"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vSDVPhjoaCH7","colab_type":"code","colab":{}},"source":["## Find the main object\n","def main_object(doc):\n","  obj = doc[0]\n","  for token in doc:\n","    if(token.dep_ == \"attr\"):\n","      obj = token\n","  return obj\n","\n","## Extract the relevant information of the main object\n","# Implement better ->\n","def extract_features(doc, main_obj_token):\n","  ## Object of interest, dependency tag = \"attr\"\n","  # obj = [token for token in doc if (token.dep_ == \"attr\")]\n","  # print(type(obj))\n","\n","  stack = []\n","  feature_lst = []\n","  stack=([child for child in main_obj_token.children])\n","\n","  while stack:\n","    token = stack.pop()\n","    feature_lst.append(token.lemma_)\n","    if(token.pos_ != \"NOUN\"):\n","      stack+=[child for child in token.children]\n","  return feature_lst\n","\n","## Creates an \"Object\" based on the given information\n","def match_features(feature_lst,main_obj_token):\n","  ob = Object(name = main_obj_token.text)\n","  for feature in feature_lst:\n","    if(isColor(feature)):\n","      ob.color = feature\n","    elif(isNumber(feature)):\n","      number = w2n.word_to_num(feature)\n","      ob.number = number\n","  return ob"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NTTzJJ1Tnvrx","colab_type":"code","colab":{}},"source":["def sentence_processing(sentence):\n","  doc = nlp(sentence)\n","  main_obj_token = main_object(doc)\n","  obj = match_features(extract_features(doc, main_obj_token), main_obj_token)\n","\n","  obj.print()\n","  return obj.to_json()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y98ynEuyKcrh","colab_type":"code","colab":{}},"source":["## MAIN ##\n","\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Get a sentence input from the user - to be deleted when merged with Speech module\n","sentence = input(\"Enter a sentence: \")\n","\n","# Store the sentence as a Spacy Doc object. Contains information on the tokens\n","doc = nlp(sentence)\n","main_obj_token = main_object(doc)\n","obj = match_features(extract_features(doc, main_obj_token), main_obj_token)\n","\n","obj.print()\n","obj.to_json()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TO9v64DEMTML","colab_type":"code","colab":{}},"source":["## Some functions to help analyzing the sentence\n","\n","# Lemma: Base form of the token, with no inflectional suffixes\n","# Part of Speech: Coarse-grained part-of-speech\n","# Tag: Fine-grained part-of-speech\n","# Dep: Syntactic dependency relation\n","\n","def display_tokens(doc):\n","  start = '\\033[36m'\n","  end = \"\\033[0;0m\"\n","  print(start.ljust(45),\"Lemma PoS Tag Dep\",end)\n","\n","  for token in doc:\n","    print(token.text.ljust(40) ,token.lemma_, token.pos_, token.tag_, token.dep_.ljust(30),\"\\t\",spacy.explain(token.dep_))\n","\n","def analyze_dependency(doc):\n","  for token in doc: \n","    print(\"Token:\",token,\"\\n\\tAncestors: \",[ancestor for ancestor in token.ancestors],\"\\n\\tChildren: \",[child for child in token.children])\n","    print(\"-------------------\")\n","\n","def dependency_tree(doc):\n","  return displacy.render(doc, jupyter=True, style='dep')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XvyDx1J6Q56Z","colab_type":"code","colab":{}},"source":["display_tokens(doc)"],"execution_count":0,"outputs":[]}]}